{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from PIL import Image\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths_env = os.getenv(\"Images\")\n",
    "mask_paths_env = os.getenv(\"Mask\")\n",
    "\n",
    " # Get the TIF files\n",
    "image_paths = os.listdir(image_paths_env)\n",
    "mask_paths = os.listdir(mask_paths_env)\n",
    "\n",
    "# Filter out fragmented files\n",
    "img_paths_new = list()\n",
    "mask_paths_new = list()\n",
    "\n",
    "for i in image_paths:\n",
    "    if i[1] not in ['_'] and '.xml' not in i:\n",
    "        img_paths_new.append(i)\n",
    "for j in mask_paths:\n",
    "    if j[1] not in ['_'] and '.xml' not in j:\n",
    "        mask_paths_new.append(j)\n",
    "\n",
    "image_paths_new = sorted(img_paths_new)\n",
    "mask_paths_new = sorted(mask_paths_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=Image.open(image_paths_env+image_paths_new[0]),Image.open(mask_paths_env+mask_paths_new[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np,y_np=np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 896, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 896)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "tensor_f=T.ToTensor()\n",
    "\n",
    "y_tensor=tensor_f(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 768, 896])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor=tensor_f(x_np)\n",
    "x_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
